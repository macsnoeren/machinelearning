{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Back propagation and gradient descent - updating weights and biases\n",
    "_Author: Maurice Snoeren_<br>\n",
    "This notebook explains back propagation and how the weights and biases are updated using gradient descent algorithm with the update rule. We will use the example that is used in an earlier notebook, which is given by the figure below.\n",
    "\n",
    "<img src=\"./images/ann1.png\" width=\"400px\" />\n",
    "\n",
    "Note that the nodes that are given have inputs, weights, biases and an activation function. This is shown by the figure below. It is important to understand this, because we will require all the forward propagation equations and functions.\n",
    "\n",
    "<img src=\"./images/perceptron2.png\" width=\"200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Training of a neural network is finding the correct weights and biases, that results in the desired output based on a given input. We could try random number for the weights and biases. However, it will take too much time because of the many possibilities. For our simple example, the neural network already contains 20 weights and 6 biases. That are already 26 different variables to fit. How do we know which variable needs to be changed? And how do we know what this change should be? We need to find a way to calculate which weights and biases need to be changed and result to the final solution.\n",
    "\n",
    "That is were gradient descent comes in. With the gradient descent algorithm we need to define the error of the neural network based on a known input and desired output. Another term for error is cost function, which is normally used within the literature. The cost function gives us an idea how bad (or how good) the solution is. It is based on a test sample $T$ that contains a predefined input $\\hat{x}$ and the belonging desired output $\\hat{y}$. When the desired output is far from the actial output, the cost function shows high costs. We define this test set as \n",
    "\n",
    "$T = [\\hat{x}, \\hat{y}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "All the neural networks will start by randomly fill the weights and biases, to have some starting point. From this moment, we are able to train the network by using samples from the test set. In this example, we will use one sample to train the network. Generally this is a bad idea. For now we are only focussing on how a neural network can be trained. When we hava a sample $T = [\\hat{x}, \\hat{y}]$, we start by calculate the output of the neural network $y$, using the forward propagation equations, based on the input vector given by $\\hat{x}$. As summary, we will give these equations below:\n",
    "\n",
    "$z_h = \\hat{x} * W_{hx} + b_h$<br>\n",
    "$h   = f(z_h)$\n",
    "\n",
    "$z_y = h * W_{yh} + b_y$<br>\n",
    "$y   = f(z_y)$\n",
    "\n",
    "We already filled in the sample input $\\hat{x}$ to the network and find the output $y$. This output is based on the current weights and biases of the network. When the network is not trained yet, the output should not show the correct solution. The error or cost can be seen as the distance between the calculated output $y$ and the desired output $\\hat{y}$. (In the literature, the calculated output is the hypothesis). We are able to calculate these by a well-known quadratic cost function (there are many types of cost functions, we will stick to this one):\n",
    "\n",
    "$J = \\frac{1}{2}(y - \\hat{y})^2$\n",
    "\n",
    "áº‚hen the calculated output and the desired output is far away, the costs will be high. Indicating that the neural network is not (yet) delivering the correct solution. If the cost is low, the output of the neural network is almost the same as desired. We could stop the training process when we reach a certain low cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which weights should be changed?\n",
    "At this point, we have a good insight how well our neural network is trained using the cost function. From now, we would like to know which weights needs to be adapted. Generally, we would like to tune the weights, that has the most influence on the cost. As example, we could change a certain weight and see how the costs are changed. When the costs are changed a lot, we know that this particular weight is able to get closer to the desired output. In the case, the costs do not change a lot, we know that this particular weight does not get us closer to the desired output. \n",
    "\n",
    "Manually changing each weight and see the effect of the cost function is very cumbersome. We can solve this by applying mathematics. In principe we would like to know how much the cost function changes when we change the weight. Within math this is done by applying the derivative of the cost function to the weight $\\frac{\\partial{J}}{\\partial{w}}$. We use partial derivative to focus on one variable only. The derivate of the cost function gives us how much the cost function will change when we change the weight. We calculate this for every weight in the network. Based on this outcome, we know which weight influence the cost function the most. That is exactly what we need.\n",
    "\n",
    "If you need to information of the derivative, you could check the following links https://www.wiskunde.net/differentieren and https://wiskundeacademie.nl/onderwerpen/de-afgeleide. Google and Youtube will have tons of information on this subject as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "When we have found the gradients of the weights $\\frac{\\partial{J}}{\\partial{w}}$ and the gradients of the biases $\\frac{\\partial{J}}{\\partial{b}}$, we are able to update our weights to improve our neural network. Updating this variables is done using the gradient descent algorithm. Within this algorithm we have the following update rule for the weights and biases respectively:\n",
    "\n",
    "$w = w - \\alpha * \\frac{\\partial{J}}{\\partial{w}}$<br>\n",
    "$b = b - \\alpha * \\frac{\\partial{J}}{\\partial{b}}$\n",
    "\n",
    "The minus sign is to move the weights and biases in the direction that the cost function become smaller. The symbol $\\alpha$ is defined as the learning rate. When $\\alpha$ is high the learning will go fast and when $\\alpha$ is low the learning is slow. Note that when the $\\alpha$ is large, it is possible the the solution is not found, due to the large steps. Change this $\\alpha$ value when you see that the neural network is not learning correctly. You can see this by plotting the cost function after each iteration. Therefore, it is a good practice to always plot the cost function versus the iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weight gradient matrix $\\frac{\\partial{J}}{\\partial{W_{yh}}}$\n",
    "The update rule of the gradient descent algorithm is used to update the weights and biases. This update rule contains the derivative of the cost to the weights and biases. We can calculate these derivatives by back propagating the network: back propagation. First we will show how to calculate the weight gradient matrices of the network. In our example, we start with the last weight matrix. Therefore, we would like to find the gradient of the weight matrix $W_{yh}$:\n",
    "\n",
    "$\\frac{\\partial{J}}{\\partial{W_{yh}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make the steps clear, the figure below shows the last layer of the network. The $h$ is the output of the nodes of the hidden layer. Als the cost function has been shows, which is the distance between the desired output and the calculated output.\n",
    "\n",
    "<img src=\"./images/bp1.png\" width=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the cost function $J$, we see that it is a function of $y$. This $y$ is in fact a function of $z_y$ and the $z_y$ is a function of ... yes ... $W_{yh}$. We could write it as functions:\n",
    "\n",
    "$\\frac{\\partial{J(W_{yh})}}{\\partial{W_{yh}}} = \\frac{\\partial{J(y(z_y(W_{yh})))}}{\\partial{W_{yh}}}$ similar to chained functions as $\\frac{\\partial{f(x)}}{\\partial{x}} = \\frac{\\partial{g( h( k(x) ) )}}{\\partial{x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the chain rule, we can multiply the derivative of each function seperately to the respective variable:\n",
    "\n",
    "$\\frac{\\partial{J(W_{yh})}}{\\partial{W_{yh}}} = \\frac{\\partial{J(y)}}{\\partial{y}} . \\frac{\\partial{y(z_y)}}{\\partial{z_y}} . \\frac{\\partial{z_y(W_{yh})}}{\\partial{W_{yh}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to solve the individual partial derivatives. Let's start!\n",
    "\n",
    "$\\frac{\\partial{J(y)}}{\\partial{y}} = \\frac{\\partial{(\\frac{1}{2}(y - \\hat{y})^2)}}{\\partial{y}} = (y - \\hat{y})$\n",
    "\n",
    "$\\frac{\\partial{y(z_y)}}{\\partial{z_y}} = \\frac{\\partial{f(z_y)}}{\\partial{z_y}} = f'(z_y)$\n",
    "\n",
    "$\\frac{\\partial{z_y(W_{yh})}}{\\partial{W_{yh}}} = \\frac{\\partial{(h * W_{yh} + b_y)}}{\\partial{W_{yh}}} = h$\n",
    "\n",
    "Taking the derivative is quite easy. If you do not understand this, you really need to check the match videos on derivative. You will see that these are very easy to solve. Note that the activation function is unknown and therefore we simply take the derivative of this function $f'(z_y)$. That means that if we choose the activation function wisely, the derivative can be very easy. At this moment, we are able to calculate the gradient of the weight matrix $W_{yh}$:\n",
    "\n",
    "$\\frac{\\partial{J(W_{yh})}}{\\partial{W_{yh}}} = (y - \\hat{y}).f'(z_y).h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the bias gradient vector $\\frac{\\partial{J}}{\\partial{b_{y}}}$\n",
    "Calculation of the gradient of the biases $b_y$ of the last layer is similar to the gradient of the weights $W_{yh}$. The last step is different, because we would like to know how the cost function changes when we change the bias vector. Therefore, we search the gradient of the biases:\n",
    "\n",
    "$\\frac{\\partial{J}}{\\partial{b_{y}}}$\n",
    "\n",
    "We are still at the same layer, so the same figure could be taken for the calculation steps.\n",
    "\n",
    "<img src=\"./images/bp1.png\" width=\"300px\" />\n",
    "\n",
    "As we have seen earlier, this consist also out of chained functions:\n",
    "\n",
    "$\\frac{\\partial{J(W_{yh})}}{\\partial{b_{y}}} = \\frac{\\partial{J(y(z_y(b_y)))}}{\\partial{b_y}}$\n",
    "\n",
    "Note that the last function is now a function of $b_y$! Applying the chain rule, we can multiply the derivative of each function seperately to the respective variable:\n",
    "\n",
    "$\\frac{\\partial{J(b_y)}}{\\partial{b_y}} = \\frac{\\partial{J(y)}}{\\partial{y}} . \\frac{\\partial{y(z_y)}}{\\partial{z_y}} . \\frac{\\partial{z_y(b_y)}}{\\partial{b_y}}$\n",
    "\n",
    "Now we are able to solve the individual partial derivatives. Let's start!\n",
    "\n",
    "$\\frac{\\partial{J(y)}}{\\partial{y}} = \\frac{\\partial{(\\frac{1}{2}(y - \\hat{y})^2)}}{\\partial{y}} = (y - \\hat{y})$\n",
    "\n",
    "$\\frac{\\partial{y(z_y)}}{\\partial{z_y}} = \\frac{\\partial{f(z_y)}}{\\partial{z_y}} = f'(z_y)$\n",
    "\n",
    "$\\frac{\\partial{z_y(b_y)}}{\\partial{b_y}} = \\frac{\\partial{(h * W_{yh} + b_y)}}{\\partial{b_y}} = 1$\n",
    "\n",
    "Only the last term need to be calculated, the other term we have already seen before. The derivative to $b_y$ become 1. At this moment, we are able to calculate the gradient of the biases vector $b_y$:\n",
    "\n",
    "$\\frac{\\partial{J(b_y)}}{\\partial{b_y}} = (y - \\hat{y}).f'(z_y).1 = (y - \\hat{y}).f'(z_y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weight gradient matrix $\\frac{\\partial{J}}{\\partial{W_{hx}}}$\n",
    "Are we ready to go to the next layer. Or in fact to a layer more closer to the input, we are in fact back propagating through the network. We need to find the gradient of the next weight matrix $W_{hx}$:\n",
    "\n",
    "$\\frac{\\partial{J}}{\\partial{W_{hx}}}$\n",
    "\n",
    "In order to make the different steps clear, we update the figure to see where we are. The figure below shows the network till we reach the matrix $W_{hx}$.\n",
    "\n",
    "<img src=\"./images/bp2.png\" width=\"600px\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reached the first hidden layer and we see the input $x$. So, there are no more layers to propagate. We will do this in the same manner as earlier. However, you see that we need to deal with a lot of functions in functions. If we write all the terms we get:\n",
    "\n",
    "$\\frac{\\partial{J(W_{hx})}}{\\partial{W_{hx}}} = \\frac{\\partial{J(y(z_y(h(z_h(W_{hx})))))}}{\\partial{W_{hx}}} = \\frac{\\partial{J(y)}}{\\partial{y}} . \\frac{\\partial{y(z_y)}}{\\partial{z_y}} . \\frac{\\partial{z_y(h)}}{\\partial{h}} . \\frac{\\partial{h(z_h)}}{\\partial{z_h}} . \\frac{\\partial{z_h(W_{hx})}}{\\partial{W_{hx}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a closer look to this equation, we see that the first two terms were also used for calculating the previous weights gradient matrix $W_{yh}$. The rest of the terms are new. Let's see if we are able to solve all the new terms.\n",
    "\n",
    "$\\frac{\\partial{z_y(h)}}{\\partial{h}} = \\frac{\\partial{(h * W_{yh} + b_y)}}{\\partial{h}} = W_{yh}$\n",
    "\n",
    "$\\frac{\\partial{h(z_h)}}{\\partial{z_h}} = \\frac{\\partial{f(z_h)}}{\\partial{z_h}} = f'(z_h)$\n",
    "\n",
    "$\\frac{\\partial{z_h(W_{hx})}}{\\partial{W_{hx}}} = \\frac{\\partial{(\\hat{x} * W_{hx} + b_h)}}{\\partial{W_{hx}}} = \\hat{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also these equations are easy to solve! That means that the gradients for matrix $W_{hx}$ can be calculated by\n",
    "\n",
    "$\\frac{\\partial{J(W_{hx})}}{\\partial{W_{hx}}} = (y - \\hat{y}).f'(z_y).W_{yh}.f'(z_y).\\hat{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first two terms $(y - \\hat{y}).f'(z_y)$ are calculated by the previous layer. So will the next two terms $W_{yh}.f'(z_y)$ be needed by the next layer. Within Python, this will be used to be able to iterate over the hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know how to derive the gradients of the weights and biases. So, you can check whether the following gradient is correct for bias $b_h$.\n",
    "\n",
    "$\\frac{\\partial{J(b_h)}}{\\partial{b_h}} = (y - \\hat{y}).f'(z_y).W_{yh}.f'(z_y)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
