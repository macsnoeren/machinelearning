{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Artificial Neuron - Perceptron\n",
    "_Author: Maurice Snoeren_<br>\n",
    "This notebook discusses the model of an artificial neuron and how this could be calculated within Python.\n",
    "<img src=\"./images/perceptron1.png\" width=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A peceptron is a single neuron. Most of the time shown by a circle with inputs and output as shown by the image above. In this example, three inputs are shown, but a perceptron could take much more inputs. Within the theory we define $n$ as the number of inputs and define the input vector ${x_1, x_2, ..., x_n}$. These inputs are multiplied by weights ${w_1, w_2, ..., w_n}$. A bias is added to this result and finally an activation function calculates the output $y$. So, a lot happens under the hood! The figure below shows the internals of the perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/perceptron2.png\" width=\"450px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\sum$ symbol is the mathematical summation of the given inputs. After this summation, the result is represented by $z$. Finally, $y$ is calculated by the (non-linear) activation function with $z$ as input. The perceptron can be calculated by the following equations:\n",
    "\n",
    "$z = b + \\sum_{i=1}^n(x_iw_i)$<br>\n",
    "$y = f(z)$\n",
    "\n",
    "When using linear algebra, we could use vectors and matrices. In this example, we could define input vector $x = [x_1, x_2, ..., x_n]$ and the weight vector $w = [w_1, w_2, ..., w_n]$. These vectors can be element-wise multiplied to get the desired result. Using vectors, the equations can be rewritten in the following form:\n",
    "\n",
    "$z = b + x*w$<br>\n",
    "$y = f(z)$\n",
    "\n",
    "Using numpy, these equations can be easily implemented in Python. In this example, we will use the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input   : [0.6 0.4 0.3]\n",
      "weights : [0.1 0.1 0.1]\n",
      "bias    : 0\n",
      "output y: [0.5149955  0.50999867 0.50749944]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x): # Sigmoid activation function\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def perceptron(x, w, b): # calculates the output of the perceptron\n",
    "    z = x*w + b\n",
    "    y = sigmoid(z)\n",
    "    return y\n",
    "\n",
    "x = np.array([0.6, 0.4, 0.3]) # inputs\n",
    "w = np.array([0.1, 0.1, 0.1]) # weights for every input\n",
    "b = 0                         # bias\n",
    "\n",
    "y = perceptron(x, w, b)\n",
    "\n",
    "print(\"input   : \" + str(x))\n",
    "print(\"weights : \" + str(w))\n",
    "print(\"bias    : \" + str(b))\n",
    "print(\"output y: \" + str(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
