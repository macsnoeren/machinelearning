{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Artificial Neuron - Perceptron\n",
    "_Author: Maurice Snoeren_<br>\n",
    "This notebook discusses the model of an artificial neuron and how this could be calculated within Python.\n",
    "<img src=\"./images/perceptron1.png\" width=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A peceptron is a single neuron. Most of the time shown by a circle with inputs and output as shown by the image above. In this example, three inputs are shown, but a perceptron could take much more inputs. Within the theory we define $n$ as the number of inputs and define the input vector ${x_1, x_2, ..., x_n}$. These inputs are multiplied by weights ${w_1, w_2, ..., w_n}$. A bias is added to this result and finally an activation function calculates the output $y$. So, a lot happens under the hood! The figure below shows the internals of the perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/perceptron2.png\" width=\"450px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\sum$ symbol is the mathematical summation of the given inputs. After this summation, the result is represented by $z$. Finally, $y$ is calculated by the (non-linear) activation function with $z$ as input. The perceptron can be calculated by the following equations:\n",
    "\n",
    "$z = b + \\sum_{i=1}^n(x_iw_i)$<br>\n",
    "$y = f(z)$\n",
    "\n",
    "When using linear algebra, we could use vectors and matrices. In this example, we could define input vector $x = [x_1, x_2, ..., x_n]$ and the weight vector $w = [w_1, w_2, ..., w_n]$. These vectors can be element-wise multiplied to get the desired result. Using vectors, the equations can be rewritten in the following form:\n",
    "\n",
    "$z = b + x*w$<br>\n",
    "$y = f(z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python example\n",
    "Using numpy, these equations can be easily implemented in Python. In this example, we will use the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input   : [1 2 3]\n",
      "weights : [2 2 2]\n",
      "bias    : 0\n",
      "z       : [2 4 6]\n",
      "y       : [0.88079708 0.98201379 0.99752738]\n",
      "output y: [0.88079708 0.98201379 0.99752738]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x): # Sigmoid activation function\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def perceptron(x, w, b): # calculates the output of the perceptron\n",
    "    z = x*w + b\n",
    "    y = sigmoid(z)\n",
    "    print(\"z       : \" + str(z))\n",
    "    print(\"y       : \" + str(y))\n",
    "    return y\n",
    "\n",
    "x = np.array([1, 2, 3]) # inputs\n",
    "w = np.array([2, 2, 2]) # weights for every input\n",
    "b = 0                   # bias\n",
    "\n",
    "print(\"input   : \" + str(x))\n",
    "print(\"weights : \" + str(w))\n",
    "print(\"bias    : \" + str(b))\n",
    "\n",
    "y = perceptron(x, w, b)\n",
    "print(\"output y: \" + str(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
